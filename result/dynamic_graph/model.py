import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# ==================== è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) ====================
def calculate_normalized_laplacian(adj):
    adj_with_selfloop = adj + torch.eye(adj.shape[0], device=adj.device)
    d = torch.sum(adj_with_selfloop, dim=1)
    d_inv_sqrt = torch.pow(d, -0.5)
    d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.
    d_mat_inv_sqrt = torch.diag(d_inv_sqrt)
    normalized_laplacian = torch.mm(torch.mm(d_mat_inv_sqrt, adj_with_selfloop), d_mat_inv_sqrt)
    return normalized_laplacian

def batch_calculate_normalized_laplacian(adj_batch):
    B, N, _ = adj_batch.shape
    I = torch.eye(N, device=adj_batch.device).unsqueeze(0).expand_as(adj_batch)
    adj_with_selfloop = adj_batch + I
    d_batch = torch.sum(adj_with_selfloop, dim=2)
    d_inv_sqrt_batch = torch.pow(d_batch, -0.5)
    d_inv_sqrt_batch[torch.isinf(d_inv_sqrt_batch)] = 0.
    d_mat_inv_sqrt_batch = torch.diag_embed(d_inv_sqrt_batch)
    L_batch = torch.bmm(torch.bmm(d_mat_inv_sqrt_batch, adj_with_selfloop), d_mat_inv_sqrt_batch)
    return L_batch

def batch_on_batch_graph_conv(x, adj_batch):
    return torch.einsum('bnm,bmd->bnd', adj_batch, x)

# ==================== æ¨¡å— 1: Cell (ä¿æŒä¸å˜) ====================
class FullyBatchedGCRNCell(nn.Module):
    def __init__(self, num_nodes, input_dim, hidden_dim, static_adj, embed_dim=32):
        super(FullyBatchedGCRNCell, self).__init__()
        self.num_nodes = num_nodes
        self.hidden_dim = hidden_dim
        self.embed_dim = embed_dim
        self.register_buffer('L_static', calculate_normalized_laplacian(static_adj))
        self.graph_fusion_alpha = nn.Parameter(torch.tensor(0.5))
        self.E_s = nn.Parameter(torch.randn(num_nodes, embed_dim))
        self.E_t = nn.Parameter(torch.randn(num_nodes, embed_dim))
        self.fc_dynamic_s = nn.Linear(input_dim + hidden_dim, embed_dim)
        self.fc_dynamic_t = nn.Linear(input_dim + hidden_dim, embed_dim)
        self.dynamic_scale = nn.Parameter(torch.tensor(0.1))
        gate_input_dim = input_dim + hidden_dim
        self.fc_r = nn.Linear(gate_input_dim, hidden_dim)
        self.fc_z = nn.Linear(gate_input_dim, hidden_dim)
        self.fc_h = nn.Linear(gate_input_dim, hidden_dim)
        self._reset_parameters()

    def _reset_parameters(self):
        nn.init.xavier_uniform_(self.E_s)
        nn.init.xavier_uniform_(self.E_t)

    def generate_time_varying_graph(self, x_t, h_t_minus_1):
        B, N, _ = x_t.shape
        A_base = torch.mm(self.E_s, self.E_t.T).unsqueeze(0).expand(B, -1, -1)
        context = torch.cat([x_t, h_t_minus_1], dim=-1)
        D_s = self.fc_dynamic_s(context)
        D_t = self.fc_dynamic_t(context)
        A_offset = torch.einsum('bnd,bmd->bnm', D_s, D_t)
        A_raw = F.relu(A_base + self.dynamic_scale * A_offset)
        return batch_calculate_normalized_laplacian(F.softmax(A_raw, dim=2))

    def forward(self, x_t, h_t_minus_1):
        # ğŸ”´ 1. æ³¨é‡Šæ‰åŠ¨æ€å›¾ç”Ÿæˆçš„è°ƒç”¨
        # L_t = self.generate_time_varying_graph(x_t, h_t_minus_1)
        
        # ğŸ”´ 2. ä¿®æ”¹èåˆé€»è¾‘ï¼šå¼ºåˆ¶åªä½¿ç”¨ L_static
        # åŸä»£ç : 
        # alpha = torch.sigmoid(self.graph_fusion_alpha)
        # A_fused = alpha * self.L_static.unsqueeze(0) + (1 - alpha) * L_t
        
        # ä¿®æ”¹ä¸ºï¼šç›´æ¥ä½¿ç”¨é™æ€ç‰©ç†å›¾
        B = x_t.shape[0]
        A_fused = self.L_static.unsqueeze(0).expand(B, -1, -1) 
        
        # ... åé¢çš„å·ç§¯æ“ä½œä¿æŒä¸å˜ ...
        x_h = torch.cat([x_t, h_t_minus_1], dim=-1)
        r = torch.sigmoid(batch_on_batch_graph_conv(self.fc_r(x_h), A_fused))
        z = torch.sigmoid(batch_on_batch_graph_conv(self.fc_z(x_h), A_fused))
        h_tilde = torch.tanh(batch_on_batch_graph_conv(self.fc_h(torch.cat([x_t, r * h_t_minus_1], dim=-1)), A_fused))
        return (1 - z) * h_t_minus_1 + z * h_tilde

# ==================== æ¨¡å— 2: Encoder (ä¿æŒåŒè¿”å›å€¼) ====================
class EnhancedGCRN_Encoder(nn.Module):
    def __init__(self, num_nodes, input_dim, hidden_dim, static_adj, num_layers=2, embed_dim=32, FullyBatchedGCRNCell=None):
        super(EnhancedGCRN_Encoder, self).__init__()
        self.num_layers = num_layers
        self.hidden_dim = hidden_dim
        self.cells = nn.ModuleList([
            FullyBatchedGCRNCell(num_nodes, input_dim if i==0 else hidden_dim, hidden_dim, static_adj, embed_dim)
            for i in range(num_layers)
        ])
        self.temporal_attention = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 4), nn.Tanh(), nn.Linear(hidden_dim // 4, 1)
        )

    def forward(self, X_seq):
        B, S, N, D = X_seq.shape
        h_list = [torch.zeros(B, N, self.hidden_dim, device=X_seq.device) for _ in range(self.num_layers)]
        X_seq = X_seq.permute(1, 0, 2, 3) 
        h_sequence = []
        
        for t in range(S):
            x = X_seq[t]
            new_h_list = []
            for l, cell in enumerate(self.cells):
                h = cell(x, h_list[l])
                new_h_list.append(h)
                x = h
            h_list = new_h_list
            h_sequence.append(h_list[-1])
        
        h_sequence = torch.stack(h_sequence, dim=1) # (B, T, N, D)
        attn = F.softmax(self.temporal_attention(h_sequence), dim=1)
        h_pooled = (h_sequence * attn).sum(dim=1)
        
        # è¿”å›ä¸¤ä¸ªå€¼
        return h_pooled, h_sequence

# ==================== æ¨¡å— 3: Decoder (æ‚¨çš„ Residual MLP) ====================
class ResidualMLPDecoder(nn.Module):
    """
    æ‚¨çš„æ®‹å·®MLPè§£ç å™¨
    """
    def __init__(self, hidden_dim, out_seq_len, num_nodes):
        super(ResidualMLPDecoder, self).__init__()
        self.out_seq_len = out_seq_len
        self.hidden_dim = hidden_dim
        
        # === 1. æ—¶é—´åµŒå…¥ ===
        self.time_embedding = nn.Embedding(out_seq_len, hidden_dim)
        
        # === 2. ä¸»åˆ†æ”¯ (MLP) ===
        self.main_branch = nn.Sequential(
            nn.Conv2d(hidden_dim, 128, kernel_size=1),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Conv2d(128, 64, kernel_size=1),
            nn.ReLU(),
            nn.Conv2d(64, out_seq_len, kernel_size=1)
        )
        
        # === 3. æ®‹å·®åˆ†æ”¯ ===
        self.residual_branch = nn.Conv2d(hidden_dim, out_seq_len, kernel_size=1)
        
        # === 4. èåˆæƒé‡ ===
        self.fusion_alpha = nn.Parameter(torch.tensor(0.7))
    
    def forward(self, h_T):
        """
        :param h_T: (B, N, hidden_dim)
        """
        B, N, D = h_T.shape
        
        # æ·»åŠ æ—¶é—´ä¿¡æ¯
        time_ids = torch.arange(self.out_seq_len, device=h_T.device)
        time_emb = self.time_embedding(time_ids).mean(dim=0, keepdim=True) # (1, D)
        h_T_enhanced = h_T + time_emb.unsqueeze(0) # (B, N, D)
        
        # è½¬æ¢ä¸º Conv2d æ ¼å¼ (B, D, N, 1)
        h_T_enhanced = h_T_enhanced.permute(0, 2, 1).unsqueeze(-1)
        
        # åˆ†æ”¯è®¡ç®—
        main_output = self.main_branch(h_T_enhanced)
        residual_output = self.residual_branch(h_T_enhanced)
        
        # èåˆ
        alpha = torch.sigmoid(self.fusion_alpha)
        output = alpha * main_output + (1 - alpha) * residual_output
        
        return output

# ==================== æ¨¡å— 4: ä¸»æ¨¡å‹ (å…³é”®ä¿®å¤) ====================
class DGCRN_Model(nn.Module):
    def __init__(self, num_nodes, static_adj, input_dim, hidden_dim, out_seq_len, 
                 num_layers=2, embed_dim=32, decoder_type='residual'): # é»˜è®¤ Residual
        super(DGCRN_Model, self).__init__()
        self.encoder = EnhancedGCRN_Encoder(num_nodes, input_dim, hidden_dim, static_adj, 
                                          num_layers, embed_dim, FullyBatchedGCRNCell)
        
        # æŒ‡å®šä½¿ç”¨ ResidualMLPDecoder
        self.decoder = ResidualMLPDecoder(hidden_dim, out_seq_len, num_nodes)
        
        print(f"âœ“ æ¨¡å‹æ„å»ºå®Œæˆ: ResidualMLPDecoder")

    def forward(self, X_seq):
        # âš ï¸ å…³é”®æ­¥éª¤: è§£åŒ…å…ƒç»„
        # encoderè¿”å› (h_pooled, h_sequence)
        # æ‚¨çš„ ResidualDecoder ä¸éœ€è¦ h_sequenceï¼Œæ‰€ä»¥ç”¨ä¸‹åˆ’çº¿ _ å¿½ç•¥å®ƒ
        h_pooled, _ = self.encoder(X_seq)
        
        # âš ï¸ å°† h_pooled (Tensor) ä¼ ç»™ decoderï¼Œè€Œä¸æ˜¯ä¼ å…ƒç»„
        Y_pred = self.decoder(h_T=h_pooled)
        
        return Y_pred.squeeze(-1)

# ==================== æµ‹è¯•ä»£ç  ====================
if __name__ == '__main__':
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = DGCRN_Model(207, torch.rand(207,207), 1, 64, 12).to(DEVICE)
    x = torch.randn(64, 12, 207, 1).to(DEVICE)
    try:
        y = model(x)
        print("âœ“ æµ‹è¯•é€šè¿‡")
        print("è¾“å‡ºå½¢çŠ¶:", y.shape) # åº”ä¸º (64, 12, 207)
    except Exception as e:
        print(f"âœ— é”™è¯¯: {e}")